{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/bencaiello/cve-dataset?scriptVersionId=143138620\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_theme()\n\nimport warnings\nwarnings.simplefilter('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-15T18:22:33.052516Z","iopub.execute_input":"2023-09-15T18:22:33.05295Z","iopub.status.idle":"2023-09-15T18:22:33.064052Z","shell.execute_reply.started":"2023-09-15T18:22:33.052915Z","shell.execute_reply":"2023-09-15T18:22:33.062809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Initial Data examination, then Data Cleaning steps\n\nConfirming relationships between the four data tables, merging of the tables, identification of duplicates, handling of null values, and work with datetime columns. \n\nOutput is the .info() of the cleaned dataframe","metadata":{}},{"cell_type":"code","source":"#access files\nfile1 = pd.read_csv('/kaggle/input/cve-common-vulnerabilities-and-exposures/products.csv')\nfile2 = pd.read_csv('/kaggle/input/cve-common-vulnerabilities-and-exposures/vendors.csv')\nfile3 = pd.read_csv('/kaggle/input/cve-common-vulnerabilities-and-exposures/cve.csv')\nfile4 = pd.read_csv('/kaggle/input/cve-common-vulnerabilities-and-exposures/vendor_product.csv')\n\n# See what's inside, and examine contents (commented out for brevity)\n'''\nprint('product: \\n', file1.head(), len(file1))\nprint('\\nvendors: \\n', file2.head(), len(file2))\nprint('\\ncve: \\n',file3.head(), len(file3))\nprint('\\nvendor_product: \\n', file4.head(), len(file4))\n\n# Look at nulls in the dataframe:\nprint('file1: \\n', file1.info())  # some NaN's in vulnerable_product column -- some cv_ids not associated with any product\nprint('file2: \\n', file2.info())  # some NaN's in vendor column -- some cv_ids not associated with any vendor (same # as missing for product)\nprint('file3: \\n', file3.info())  # ~half of the columns are complete, ~1/2 are missing a small number of values [same # of values in each column]\nprint('file4: \\n', file4.info())  # no null values\n\n# Relationships between tables in the dataset:\n# Main file about the cves of use seems to be file3:\n    # file1 supplies connection between cve_id and product\n    # file 2 supplies connection between cve_id and vendor\n    # file 4 supplies conncetion between vendor and product\n    \n# Look at duplicate values:\nlendupfile1 = len(file1[file1['cve_id'].duplicated() == True])\nprint(lendupfile1, '  ' , len(file1) - lendupfile1)\nprint('Number of identical, unique cve values shared in file1,file2 and file3 [all = 89660, the length of file3]')\n\n# slightly more than half of the cve_ids are duplicated, indicating vulnerabilities that affect more than one product.\nprint(sum(file1['cve_id'].unique() == file3['Unnamed: 0'].unique()))\n\n# perfect correspondance between unique cve_id's in file1 and cve_ids in file2 and file3\n\nprint(sum(file3['Unnamed: 0'].unique() == file2['Unnamed: 0'].unique()))\n\n# but obviously the cve_id corresponds to more than one vendor / product for many of the cve_ids\nprint('count of vendor unique values in file 2 and 4')\nprint(len(file2['vendor'].unique()))\nprint(len(file4['vendor'].unique()))\n\nprint('count of product unique values in file 1 and 4')\nprint(len(file1['vulnerable_product'].unique()))\nprint(len(file4['product'].unique()))\n'''\n\n\n# Now I will drop nulls in file3 as for each column they are in they are <5% of the values in those columns\nfile3 = file3.dropna()\n\n\n## Merge files:\n# May work with original file (file3, or a a merge of file 2/3) just to use less computation per calculation. But if things aren't slowed down too much, I won't bother.\nfile3 = file3.rename(columns = {'Unnamed: 0':'cve_id'})\nfile2 = file2.rename(columns = {'Unnamed: 0':'cve_id'})\n\n#if we want to merge everything (file 4 is dispensable, I think) \nfile13 = file1.merge(file3)\nfile123 = file13.merge(file2)\n\n#file123.info()\n#file123.head()\n\n\nsum(file123.duplicated())  # equals zero, so no duplicates. To see, wrap in a print statement or run on its own by ctrl-shift-enter in the notebook\n\n# Convert date columns to datetime\nfile123['mod_date'] = pd.to_datetime(file123['mod_date'])\nfile123['pub_date'] = pd.to_datetime(file123['pub_date'])\n\n# just make the mod date a function of the publication date\nfile123['mod_date'] = file123['mod_date'] - file123['pub_date'] \n\n# only remaining nulls (after dropping the null columns in file 3 earlier) are in the vendor/product columns that would represent cve's without a value in that column\n# if the product is missing, it can't be filled easily, but if the vendor is missing, it may be inferrable from the product\n# the description may also provide info\n# But first: take a look at the NaN rows--\n\n# print(file123[file123['vulnerable_product'].isna()])  # uncomment to run\n\n# all NaN products are also the NaN vendors\n# let's look at summary\npd.options.display.max_colwidth=500\n# print(file123[file123['vendor'].isna()]['summary'].head(n=1)) # uncomment to see output\n# checked one of the summaries, the only indicative word of vendor or product was 'oVirt'\nfile123 = file123.dropna()\nfile123[file123['vulnerable_product'].str.contains('oVirt')]\n\n# no oVirt in product list -- will simply drop NaNs, as has already been done and not try to salvage NaNs in vendor/product columns\nprint(file123.info())","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-15T18:22:33.066548Z","iopub.execute_input":"2023-09-15T18:22:33.067209Z","iopub.status.idle":"2023-09-15T18:22:37.570402Z","shell.execute_reply.started":"2023-09-15T18:22:33.067163Z","shell.execute_reply":"2023-09-15T18:22:37.569273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization: CVSS scores -- overall distribution\n\n\nNow that nulls are gone, and the data relatively clean, we can start to look at it","metadata":{}},{"cell_type":"code","source":"# looking at what a cvss score is: https://nvd.nist.gov/vuln-metrics/cvss. As it is a numerical way of scoring the severity of a threat, this is likely our main target metric (for most plots)\n# CVSS is also almost the only numerical column in the dataset, except perhaps the mod_date, now that that column is a change in time from publication date.\n# The other columns are all categorical or descriptive. This means I likely will mainly be using categorical plots / grouped data methods for visualization.\n\nsns.histplot(data = file123, x ='cvss', bins = 20)\nplt.title(\"Overall Distribution of CVSS scores in the Dataset\")\nplt.show()\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-15T18:22:37.572377Z","iopub.execute_input":"2023-09-15T18:22:37.57277Z","iopub.status.idle":"2023-09-15T18:22:38.038425Z","shell.execute_reply.started":"2023-09-15T18:22:37.572717Z","shell.execute_reply":"2023-09-15T18:22:38.037261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizations (cont.): most affected vendors","metadata":{}},{"cell_type":"code","source":"top_vend = file123['vendor'].value_counts().head(n = 50)\ntop = list(top_vend.index)\n\ntop_vend.plot(kind = 'bar')\nplt.title(\"The 50 Most Frequently Affected Companies\")\nplt.ylabel('Number of CVEs')\nplt.xticks(rotation = 90, size = 8)\nplt.show()\n\nfile123_top = file123[file123['vendor'].isin(top)]\nsns.barplot(x = 'vendor', y = 'cvss', data = file123_top, order = top)\nplt.title(\"Mean CVSS Score Across the 50 Most Frequently Affected Companies\")\nplt.xticks(rotation = 90, size = 8)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-15T18:22:38.04008Z","iopub.execute_input":"2023-09-15T18:22:38.041267Z","iopub.status.idle":"2023-09-15T18:22:43.621791Z","shell.execute_reply.started":"2023-09-15T18:22:38.04123Z","shell.execute_reply":"2023-09-15T18:22:43.620561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizations: Top Affected products","metadata":{}},{"cell_type":"code","source":"top_prod = file123['vulnerable_product'].value_counts().head(n = 50)\ntop_p = list(top_prod.index)\n\ntop_prod.plot(kind = 'bar')\nplt.title(\"The 50 Most Frequently Affected Products\")\nplt.ylabel('Number of CVEs')\nplt.xticks(rotation = 90, size = 8)\nplt.show()\n\nfile123_top_p = file123[file123['vulnerable_product'].isin(top_p)]\nsns.barplot(x = 'vulnerable_product', y = 'cvss', data = file123_top_p, order = top_p)\nplt.title(\"Mean CVSS Score Across the 50 Most Frequently Affected Products\")\nplt.xticks(rotation = 90, size = 8)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-15T18:22:43.624743Z","iopub.execute_input":"2023-09-15T18:22:43.625124Z","iopub.status.idle":"2023-09-15T18:22:48.135686Z","shell.execute_reply.started":"2023-09-15T18:22:43.625092Z","shell.execute_reply":"2023-09-15T18:22:48.134519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization: Operating systems","metadata":{}},{"cell_type":"code","source":"# In the product bar-charts above we can see a lot of \"linux\" or \"windows\" in the names\n# let's see if we can extra information about the OS from the product name\n\nfile123['is_linux'] = np.where(file123['vulnerable_product'].str.lower().str.contains('linux'), 1, 0)\nfile123['is_android'] = np.where(file123['vulnerable_product'].str.lower().str.contains('android'), 2, 0)\nfile123['is_unix'] = np.where(file123['vulnerable_product'].str.lower().str.contains('unix'), 3, 0)\nfile123['is_chrome'] = np.where(file123['vulnerable_product'].str.lower().str.contains('chrome_os'), 4, 0)\nfile123['is_windows'] = np.where(file123['vulnerable_product'].str.lower().str.contains('windows'), 5, 0)\nfile123['is_mac'] = np.where(file123['vulnerable_product'].str.lower().str.contains('mac_os'), 6, 0)\nfile123['is_iphone'] = np.where(file123['vulnerable_product'].str.lower().str.contains('iphone_os'), 7, 0)\n\nfile123['os'] = file123['is_iphone'] + file123['is_linux'] + file123['is_mac'] + file123['is_android'] + file123['is_chrome'] + file123['is_windows'] + file123['is_unix']\n\n# take a look inside 'mac' (as I have a choice of searching for 'mac' or 'mac_os'): (uncomment to run)\n# print(file123[file123['vulnerable_product'].str.lower().str.contains('mac')])\n# Top result is 'maconomy', simple google search reveals this has nothing to do with mac_os.... so 'mac_os' it is!\n\n\n# compare counts of individual columns vs. combined result: one windows + unix (value = 8) product\n# note this is after re-ordering columns and refining str.contains('statements'). \n# Of note, I added \"_os\" to the chrome search, which greatly reduced the number of hits for chrome (presumably excluding the browser)\n# Importantly, this also reduced the number of overlapped values to 2 (using 'mac_os' instead of 'mac' reduces this to 1). \n'''\n# Uncomment code block to see test/comparison of the individual columns to the singular os column:\nprint(0)\nprint(sum(file123['is_linux']))\nprint(sum(file123['is_android'] / 2))\nprint(sum(file123['is_unix'] / 3))\nprint(sum(file123['is_chrome'] / 4))\nprint(sum(file123['is_windows'] / 5))\nprint(sum(file123['is_mac'] / 6))\nprint(sum(file123['is_iphone'] / 7))\n\nprint(file123['os'].value_counts().sort_index())\n'''\n# Now, let's plot:\n\nlabels_by_order = ['linux', 'windows', 'mac_os', 'android', 'iphone_os', 'chrome_os', 'unix', 'unix & windows']\nlabels_by_order_with_non_os = ['non-OS / Other', 'linux', 'windows', 'mac_os', 'android', 'iphone_os', 'chrome_os', 'unix', 'unix & windows']\nOS_count = file123['os'].value_counts()[1:]\n\nOS_count.plot(kind = 'bar')\nplt.title(\"CVEs by OS\")\nplt.ylabel('Number of CVEs')\nplt.xticks(rotation = 90, size = 8, ticks = [0, 1, 2, 3, 4, 5, 6, 7], labels = labels_by_order)\nplt.show()\n\nsns.barplot(x = 'os', y = 'cvss', data = file123)\nplt.title(\"Mean CVSS Score Across the OS Categories\")\nplt.xticks(rotation = 90, size = 8, ticks = [0, 1, 2, 3, 4, 5, 6, 7, 8], labels = labels_by_order_with_non_os)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-15T18:22:48.13701Z","iopub.execute_input":"2023-09-15T18:22:48.137435Z","iopub.status.idle":"2023-09-15T18:22:53.87728Z","shell.execute_reply.started":"2023-09-15T18:22:48.1374Z","shell.execute_reply":"2023-09-15T18:22:53.876092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Perhaps this might have to do with the open-source nature of linux making its CVE's more frequently/easily reported? Linux has dramatically more CVE's in this dataset but the mean CVSS score is noticeably lower than the other common OS's.\n\n\n\nCaveats: not all OS's are captured in this graph, and it is likely that my search terms may have excluded some as well (for example, 'mac_os' as a search term might miss some mac operating systems. It reduced the number of cve's in that search by ~1200 events, compared to only searching for 'mac'. However, I chose the more exclusive term to remove programs, like 'maconomy' that might show up in my results with a less stringent search)","metadata":{}},{"cell_type":"markdown","source":"# CVSS score across access methods and impact on different parts of the CIA triad\n","metadata":{}},{"cell_type":"code","source":"cols = file123.columns[8:14]\nfile123['access_vector'] = file123['access_vector'].str.replace('_NETWORK', ' NET')\n\nfig, ax = plt.subplots(nrows = 2, ncols = 3, sharey = True, layout = 'constrained', figsize = (8, 7))\ni = 0\nfor axs in ax.flat:\n    if i < 3:\n        sns.barplot(x = cols[i], y = 'cvss', data = file123, ax = axs)\n    else:\n        sns.barplot(x = cols[i], y = 'cvss', data = file123, ax = axs, order = ['NONE', 'PARTIAL', 'COMPLETE'])\n    axs.set_title('CVSS score by \\n{}'.format(cols[i]), size = 10)\n    i += 1\n    axs.tick_params(labelrotation = 90, labelsize = 6)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T18:22:53.879209Z","iopub.execute_input":"2023-09-15T18:22:53.879628Z","iopub.status.idle":"2023-09-15T18:23:14.161288Z","shell.execute_reply.started":"2023-09-15T18:22:53.87959Z","shell.execute_reply":"2023-09-15T18:23:14.160409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization of CVE's over time","metadata":{}},{"cell_type":"code","source":"'''\ncols = file123.columns[8:14]\n\nfor i in cols:\n    print(i, '\\n', file123[i].value_counts().index)\n'''\n\nsns.displot(file123, x = 'pub_date', kind = 'ecdf', stat = 'count')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-15T18:23:14.162638Z","iopub.execute_input":"2023-09-15T18:23:14.163626Z","iopub.status.idle":"2023-09-15T18:23:15.184709Z","shell.execute_reply.started":"2023-09-15T18:23:14.163588Z","shell.execute_reply":"2023-09-15T18:23:15.183624Z"},"trusted":true},"execution_count":null,"outputs":[]}]}