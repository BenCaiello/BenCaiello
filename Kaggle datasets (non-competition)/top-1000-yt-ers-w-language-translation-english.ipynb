{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/bencaiello/top-1000-yt-ers-w-language-translation-english?scriptVersionId=143564267\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_theme()\n\n\n# Install translation package (only need to do once!)\ntry:\n    import translators as ts\nexcept:\n    !pip install translators\n    import translators as ts\n\nimport warnings\nwarnings.simplefilter('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        filepath = (os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-19T19:34:39.533897Z","iopub.execute_input":"2023-09-19T19:34:39.534312Z","iopub.status.idle":"2023-09-19T19:34:39.547866Z","shell.execute_reply.started":"2023-09-19T19:34:39.534279Z","shell.execute_reply":"2023-09-19T19:34:39.547053Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note that this first step may run slowly if you copy this notebook, as a download from pip is used for the translation package. This only should occur on the first run of the notebook.","metadata":{}},{"cell_type":"markdown","source":"# Introduction & First Look at Data!\n\nThere is also so data cleaning / rearranging going on insde the hidden code block -- expand to check!","metadata":{}},{"cell_type":"code","source":"file = pd.read_csv(filepath)\n\n# Inspect the nture of the data in each column, the number of null values and the datatypes of the columns\ndisplay(file.head())\ndisplay(file.info())\n\n#  The numerical columsn do not need to be floats as they represent. \n# Note: trying to read these columns (3,5-7) directly as 'int' type did not succeed.\nfor i in file.columns:\n    try:\n        file[i] = file[i].astype('int')\n    except:\n        pass\n\n# The Country column, although having no null values has 'Unknown' values\n# Will convert the nulls in categories to 'Unknown' for consistency.\n# Cannot drop nulls becaues there are too many in the categories column\nfile['Categories'] = file['Categories'].fillna('Unknown')\n\n# Additionally, I will drop the links column (at least for now), as it does not provide useful information for most visualizations.\nfile = file.drop('Links',axis = 1)\n\n# I will also create a column of subscribers in millions (easier to plot)\nfile['Subscribers (millions)'] = file['Suscribers'] / 1000000","metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-19T19:34:39.597117Z","iopub.execute_input":"2023-09-19T19:34:39.597678Z","iopub.status.idle":"2023-09-19T19:34:39.632384Z","shell.execute_reply.started":"2023-09-19T19:34:39.59765Z","shell.execute_reply":"2023-09-19T19:34:39.631109Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Translation of Category and Country columns to English\n\nAlong the way, I also convert the category column into a column of lists (instead of a column of strings), as each channel can have more than one category.","metadata":{}},{"cell_type":"code","source":"# I am a monolingual English speaker -- so let's convert the country / category names into English!\n# Link to package:  https://pypi.org/project/translate-api/\n# Note that documentation at the provided link is inaccurate!\n\n# First, identify the categories in the Categories columns. Note that some channels are more than one category.\ncat_list = []\nfor i in file['Categories']:\n    split_list = []\n    split_list = i.split(',')\n    for j in split_list:\n        j = j.strip()\n        cat_list.append(j)\n\n# Now I isolate the unique categories, by using the set datatype:\ncat_set = set(cat_list)\n\n\n# Next, I convert the unique categories into a single string of each category, separated by commas.\n# This is important to reduce the number of queries to the translation tool / URL to a minimum.\n# The translate_text function throws an error if you query the same URL more than ~7 times in rapid succession.\ncat_list = list(cat_set)\ncat_str = ''\nfor i in cat_list:\n    cat_str = cat_str + i + ','\n    \n# Now we translate:\nenglish = ts.translate_text(cat_str)\n\n# Then undo the single string back into a list:\nenglish_list = english.split(',')\n\n# Then make a dictionary to match the Spanish phrases to the English translations.\ntrans_dict = {}\nfor i,ii in enumerate(cat_list):\n    trans_dict[ii] = english_list[i]\n    \n# Next we translate the column using the dictionary:\ntranslation_list = []\nfor i in file['Categories']:\n    entry = i.split(',')\n    entry_list = []\n    for j in entry:\n        j = j.strip()\n        j = trans_dict[j]\n        entry_list.append(j)\n    translation_list.append(entry_list)\nfile['Categories'] = translation_list\n\n# Countries are much simpler, as they only have singular values per entry:\n# A similar process is followed as above, with fewer steps. \n# Consult the comments above if you want to understand why each step is taken\ncountry_list = list(file['Country'].unique())\ncountry_str = ''\nfor i in country_list:\n    country_str = country_str + i + ','\nenglish_c = ts.translate_text(country_str)\nenglish_list_c = english_c.split(',')\ntrans_dict = {}\nfor i,ii in enumerate(country_list):\n    trans_dict[ii] = english_list_c[i]\nfile['Country'] = file['Country'].replace(trans_dict)\n\ndisplay(file.head())","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-19T19:34:39.664674Z","iopub.execute_input":"2023-09-19T19:34:39.665084Z","iopub.status.idle":"2023-09-19T19:34:40.347433Z","shell.execute_reply.started":"2023-09-19T19:34:39.665053Z","shell.execute_reply":"2023-09-19T19:34:40.346133Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make dummy variables for every category & begin to plot!","metadata":{}},{"cell_type":"code","source":"# Make dummy variable columns!\nenglish_list = english_list[0:-1]\nfor i in english_list:\n    T_F_list = []\n    for j in file['Categories']:\n        if i in j:\n            T_F_list.append(1)\n        else:\n            T_F_list.append(0)\n    file[i] = T_F_list\ndisplay(file.head())\n\n# change likes / comments in main dataframe so they can be plotted as log-values:\nfile['Likes'] = (file['Likes'] + 0.01) / 10000\nfile['Comments'] = (file['Comments'] + 0.001) / 1000\nfile['Visits'] = (file['Visits'] + 0.001) / 10000\n\n# Look at distribution of numerical variables:\ndist_list = ['Subscribers (millions)','Likes','Comments','Visits']\ndist_df = file[dist_list]\n\nsns.boxplot(dist_df)\nplt.title('Distribution of Subs (in millions), Likes (1000s), Comments (1000s), & Visits (1000s)')\nplt.show()\n\nprint('\\n The data is extremely skewed! \\n')\n\nsns.boxplot(dist_df)\nplt.title('Distribution of Subs (in millions), Likes (1000s), Comments (1000s), & Visits (1000s) on Log scale')\nplt.yscale('log')\nplt.show()\n\nprint('\\n Will use log distribution when plotting likes/comments! \\n')\n\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-19T19:34:40.349797Z","iopub.execute_input":"2023-09-19T19:34:40.350169Z","iopub.status.idle":"2023-09-19T19:34:40.899186Z","shell.execute_reply.started":"2023-09-19T19:34:40.35014Z","shell.execute_reply":"2023-09-19T19:34:40.897492Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Categories: Counts and AVG Subscribers by category","metadata":{}},{"cell_type":"code","source":"# Make a data frame with all the categories of channel\n# Note that this has to be a new dataframe, as it will bel onger than 1000\n\ncat_counts = pd.DataFrame()\ncat_list = []\nfor i in file['Categories']:\n    for j in i:\n        cat_list.append(j)       \ncat_counts['Categories'] = cat_list\ncat_count_ordered_list = cat_counts['Categories'].value_counts().index\n\nsns.countplot(x=cat_counts['Categories'], order = cat_count_ordered_list)\nplt.xticks(rotation=90)\nplt.title('Channel Counts of Each Category')\nplt.xlabel(None)\nplt.show()\n\nloop_dict = {}\ni = 10\nwhile i < 33:\n    loop_list = file[file[file.columns[i]] == 1]['Subscribers (millions)']\n    loop_dict[file.columns[i]] = loop_list\n    i += 1\nloop_dict['Overall'] = file['Subscribers (millions)']\n\ncats = pd.DataFrame(loop_dict)\ncat_order = cats.mean().sort_values().index\nov_mean = loop_dict['Overall'].mean()\n\n\nsns.barplot(cats, order = list(cat_order),color = 'r')\nplt.xticks(rotation = 90)\nplt.title('Average Subscribers by Category')\nplt.ylabel('AVG Subscribers (Millions)')\nplt.hlines(ov_mean,xmin = 0, xmax = 24, linestyles = 'dashed' )\nplt.annotate('Avg subs',xy=(0,ov_mean),size = 10)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-19T19:34:40.901015Z","iopub.execute_input":"2023-09-19T19:34:40.901378Z","iopub.status.idle":"2023-09-19T19:34:43.180303Z","shell.execute_reply.started":"2023-09-19T19:34:40.901345Z","shell.execute_reply":"2023-09-19T19:34:43.179481Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Only four categories outperform the overall average: Toys, Music & Dance, Education, Video Games, and Animation!**","metadata":{}},{"cell_type":"markdown","source":"# Now by Country!","metadata":{}},{"cell_type":"code","source":"country_counts = file['Country'].value_counts().index\n\nsns.countplot(x=file['Country'], order = country_counts)\nplt.xticks(rotation=90)\nplt.title('Channel Counts of Each Country')\nplt.xlabel(None)\nplt.show()\n\navg_subs_per_country_list = file.groupby('Country')['Subscribers (millions)'].mean().sort_values().index\n\nsns.barplot(file, x = file['Country'], y = 'Subscribers (millions)', order = list(avg_subs_per_country_list),color = 'r')\nplt.xticks(rotation = 90)\nplt.title('Average Subscribers by Category')\nplt.ylabel('AVG Subscribers (Millions)')\nplt.hlines(ov_mean,xmin = 0, xmax = 29, linestyles = 'dashed' )\nplt.annotate('Avg subs',xy=(0,ov_mean + 1),size = 10)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-19T19:34:43.18268Z","iopub.execute_input":"2023-09-19T19:34:43.183258Z","iopub.status.idle":"2023-09-19T19:34:44.531888Z","shell.execute_reply.started":"2023-09-19T19:34:43.183225Z","shell.execute_reply":"2023-09-19T19:34:44.531006Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Once again, only a few countries exceed the average subs / channel! Likely the high number of India and 'Unknown' country channels and their relatively higher subscribed count are pulling up the overall average.**","metadata":{}},{"cell_type":"markdown","source":"# Test the Pareto Distribution! Do 20% of the channels have 80% of the Subscribers?\n\n\nThe Pareto distribution is a principle about how the top few percent possess or produce the majority of a given resource -- perhaps in this case, something like YT subscribers?\n\nOne name for this is the \"80-20\" rule, aka that 80 of the given resource (the principle was originally discovered in terms of wealth) is held by only 20% people. \n\n[Follow this link to see a discussion of this principle, & as a source!](https://dlab.berkeley.edu/news/explaining-80-20-rule-pareto-distribution#:~:text=The%20Pareto%20distribution%20is%20a%20power%2Dlaw%20probability%20distribution%2C%20and,sloped%20(see%20Figure%201).)\n\nOne wrinkle here, is that we are looking at the top 1000 channels, not all the channels on Youtube.","metadata":{}},{"cell_type":"code","source":"plt.bar(x=file.index,height=file['Subscribers (millions)'],edgecolor = 'b',color = 'b')\nplt.vlines(200, ymin = 0, ymax = 250,color = 'r')\nplt.annotate('Top 20%',xy = (10,250), size = 10)\nplt.annotate('Lower 80%',xy = (250,250), size = 10)\nplt.title('Distribution of Subs in order of rank')\nplt.ylabel('Subscribers (millions)')\nplt.xlabel('Rank')\nplt.show()\n\nfile['Subscribers cumulative (mil)'] = file['Subscribers (millions)'].cumsum()\n\nsns.displot(y = file['Subscribers cumulative (mil)'], kind = 'ecdf')\nplt.vlines(0.2, ymin = 0, ymax = file['Subscribers cumulative (mil)'][999],color = 'r')\nplt.annotate('Top 20%',xy = (0,21000), size = 10)\nplt.annotate('Lower 80%',xy = (0.21,21000), size = 10)\nplt.xlabel('Proportion of Channels included in Cumulative Subscribers')\nplt.title('Cumulative Subscribers over top 1000 YT channels')\nplt.show()\n\ntwenty = file['Subscribers cumulative (mil)'][199]\ntotal = file['Subscribers cumulative (mil)'][999]\neighty = total - twenty\n\nprint('Number of Subscribers from top 200 channels (in millions): ', round(twenty, 3))\nprint('% of total: ', round(twenty / total, 3) * 100)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-19T19:34:44.532987Z","iopub.execute_input":"2023-09-19T19:34:44.533274Z","iopub.status.idle":"2023-09-19T19:34:46.223938Z","shell.execute_reply.started":"2023-09-19T19:34:44.533249Z","shell.execute_reply":"2023-09-19T19:34:46.223035Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Answer:**\n\nNo! here 20% of the top 1000 YT channels have 40% of their subscribers, not 80%!","metadata":{}},{"cell_type":"markdown","source":"# What about comments and likes?\n\nLet's look at how engagement per video tracks with total subscribers!\n\nNote that subscribers are in millions, while the others are in units of 1,000s before the log transformation.","metadata":{}},{"cell_type":"code","source":"# Plot these columns after log transformation\nfile['log Likes'] = np.log(file['Likes'])\nfile['log Comments'] = np.log(file['Comments'])\nfile['log Subs'] = np.log(file['Subscribers (millions)'])\nfile['log Visits'] = np.log(file['Visits'])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-19T19:34:46.22516Z","iopub.execute_input":"2023-09-19T19:34:46.225456Z","iopub.status.idle":"2023-09-19T19:34:46.235824Z","shell.execute_reply.started":"2023-09-19T19:34:46.225433Z","shell.execute_reply":"2023-09-19T19:34:46.234049Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr = np.corrcoef(file['log Likes'],file['log Subs'])\ncorrelation = 'corr = ' + str(round(corr[0][1],2))\n\n\nsns.regplot(file,x='log Subs',y = 'log Likes', ci = None, line_kws = {'color':'r', 'linestyle':'dashed'})\nplt.title('Likes per video vs. Subscribers (logarithmic scale)')\nplt.annotate(correlation, xy = (5,0.1), size = 10)\nplt.show()\n\ncorr = np.corrcoef(file['log Comments'],file['log Subs'])\ncorrelation = 'corr = ' + str(round(corr[0][1],2))\n\nsns.regplot(file,x='log Subs',y = 'log Comments', ci = None, line_kws = {'color':'r', 'linestyle':'dashed'})\nplt.title('Comments per video vs. Subscribers (logarithmic scale)')\nplt.annotate(correlation, xy = (4.5,-7.5), size = 10)\nplt.show()\n\ncorr = np.corrcoef(file['log Visits'],file['log Subs'])\ncorrelation = 'corr = ' + str(round(corr[0][1],2))\n\nsns.regplot(file,x='log Subs',y = 'log Visits', ci = None, line_kws = {'color':'r', 'linestyle':'dashed'})\nplt.title('Visits per video vs. Subscribers (logarithmic scale)')\nplt.annotate(correlation, xy = (4.75,2), size = 10)\nplt.show()\n\n\ncorr = np.corrcoef(file['log Comments'],file['log Likes'])\ncorrelation = 'corr = ' + str(round(corr[0][1],2))\n\nsns.regplot(file,x='log Likes',y = 'log Comments', ci = None, line_kws = {'color':'r', 'linestyle':'dashed'})\nplt.title('Comments per video vs. Likes (logarithmic scale)')\nplt.annotate(correlation, xy = (-12,-10), size = 10)\nplt.show()\n\ncorr = np.corrcoef(file['log Visits'],file['log Likes'])\ncorrelation = 'corr = ' + str(round(corr[0][1],2))\n\nsns.regplot(file,x='log Likes',y = 'log Visits', ci = None, line_kws = {'color':'r', 'linestyle':'dashed'})\nplt.title('Visits per video vs. Likes (logarithmic scale)')\nplt.annotate(correlation, xy = (-12,-10), size = 10)\nplt.show()\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-19T19:34:46.23725Z","iopub.execute_input":"2023-09-19T19:34:46.237812Z","iopub.status.idle":"2023-09-19T19:34:47.578083Z","shell.execute_reply.started":"2023-09-19T19:34:46.237773Z","shell.execute_reply":"2023-09-19T19:34:47.576416Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Per Video Likes and Visits / Comments correlate well with each other -- but these do not strongly correlate with subscribe count!**","metadata":{}}]}